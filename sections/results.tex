

%% Consider a network with nodes $x_1,\dots,x_{N}$. Let there be a connection from node $x_i$ to $x_j$ with probability $P_{ij}$. Typically, . However, it is highly unlikely that all nodes are connected with the same probability. 

%% Thus let the $P_{ij}$ be identically distributed continuous random variables with values in $[0,1]$. We write the of probability density function of the $P_{ij}$ as $f_{P_{ij}}$.


%% We're discussing now a network model in which node-to-node connection probabilities are randomly distributed. One might think for example of a network in which connection probability decreases with distance.

%% Remembering the notation from above, we write
%% \[
%% P(X_{ij}=1) = P_{ij}
%% \]
%% where $P=P_{ij}$ are identically distributed continuous random variables with values in $[0,1]$. We write the of probability density function of the $P_{ij}$ as $f_{P_{ij}}$.

\cc{[Felix: Please read next 3 paragraphs carefully and let me know whether it has improved. I tried to address all of your concerns and comments.]}
The emergence of non-random connectivity patterns can be modeled by
assigning each possible connection in a random graph a separate
probability to exist.
%
In such a model some connections are more likely to be realized than
others, allowing for the encoding of patterns within the specific
probabilities of each connection.
%
In the limiting case each connection either exists or is absent with
certainty, representing a blueprint for the network architecture.
%

%
To analyze the effect of non-random structures within a network,
specifically on the statistics of bidirectionally connected pairs
found in the network, we consider a random graph model of $N$ neurons
in which a connection from node $i$ to node $j$ exists with
probability $P_{ij}$.
%
Here the $P_{ij}$, with $i,j = 1,\dots,N$ and $i \neq j$, are identically
distributed random variables in $[0,1]$, yielding a probability of
connection for each ordered pair of nodes in the graph. We explicitly exclude self-connections in this model and assume at all times that $i \neq j$.% Below we're assuming $i \neq j $ in all cases.
% where we
%always assume $i \neq as it does not make sense to consider
%bidirectional connectivity in
%% self-connections.
%

%
Given the distributions of connection probabilities, what is
then the probability in this model for a randomly selected node to have a
projection to another randomly selected node?
%
As the random variables $P_{ij}$ are identically distributed, we
compute this overall connection probability $\mu$ easily as the
expected value of~$P_{ij}$,
\begin{align}
\mu = \E(P_{ij}).
\end{align}
%
\cc{[Felix: You asked: \enquote{Do we need to clarify what exactly we mean with the expected value? A possible confusion could arise regarding whether we also sum over pairs $P_{ii}$ or not. I assume you donâ€™t, but is it really clear?} \\ It doesn't seem to be clear. There's actually no summation at all. Since the $P_{ij}$ (excluding $i=j$) are identically distributed,
\begin{align}
  \E\left(\frac{1}{N(N-1)} \sum_{i \neq j} P_{ij} \right) = \E(P_{ij})
\end{align}
Since all $P_{ij}$ (again excluding $i=j$) are identically distributed and only the probability distribution matters for the expected value, I believed writing $\E(P_{ij})$ is clear enough, referring to the expected value of any (and thus of all) $P_{ij}$. The equation I wrote above seems redundant, please make a suggstion how to make things more clear. I added some expression that might help.]}\\
%% Here, we are interested in the probability $P_{\mathbf{bidir}}$ of finding In a random pair of neurons, the probability  to find a bidirectional connection is the expected value of the product of $P=P_{ij}$ and $Q=P_{ji}$. With their respective density functions $f_P$, $f_Q$ and their joint probability density function $f_{PQ}$ we have
%
%
In this work we are interested in the probability $P_{\mathbf{bidir}}$
of a bidirectional connection to exist in a random pair of neurons.
%
We determine $P_{\mathbf{bidir}}$ as the expected value of the product
of $P_{ij}$ and $P_{ji}$,
%
\begin{align}
P_{\mathbf{bidir}} = \E(P_{ij} P_{ji}).
\end{align}
%
The relative occurrence $\varrho$ of such reciprocally connected pairs compares $P_{\mathbf{bidir}}$ with the occurrence of bidirectional pairs in an Erd\H{o}s-R\'{e}nyi graph, in which each unidirectional connection is equally likely to occur with probability $\mu$ \cite{Gilbert1959, Erdos1959}. The probability of a particular bidirectional connection to exist in such a random graph is simply $\mu^2$ and we obtain the relative occurrence as the quotient
%% To answer the question if this probability is deviates from the proabibility than we would expect . The probability of a bidirectional in this standard random graph is $\mu$. We can the overrepresentation of as the quotient of $
\begin{align}
\varrho = \frac{P_{\mathbf{bidir}}}{\mu^2} = \frac{\E(P_{ij}P_{ji})}{{\E\left(P_{ij}\right)}^2}.
\end{align}
%
Experimental studies in local cortical circuits of rodents have repeatedly reported a relative occurrence of bidirectional connections $\varrho > 1$ \cite{Markram1997, Song2005, Perin2011}. To understand in which cases such an overrepresentations occurs, we consider two cases. In the first case, assume that the random variables $P_{ij}$ and $P_{ji}$ are independent. Then
\begin{align}
\E(P_{ij} P_{ji}) = \E(P_{ij})\,\E(P_{ji}) = \E(P_{ij})^2,
\end{align}
and we expect to observe no overrepresentation of reciprocal connections, $\varrho = 1$.  In the second case, assume that connection probabilities are symmetric in pairs, $P_{ij} = P_{ji}$. In this case,
\begin{align}
P_{\mathbf{bidir}} = \E(P_{ij}^2),
\end{align}
%
and the relative occurrence of reciprocal connections becomes
\begin{align}
\varrho = \frac{\E(P_{ij}^2)}{{\E\left(P_{ij}\right)}^2}.
\end{align}
We note that now any distribution of $P_{ij}$ with a nonvanishing
variance will lead to a relative occurrence that deviates from the
Erd\H{o}s-R\'{e}nyi graph, as
\begin{align}
\Var(P_{ij}) = \E(P_{ij}^2) - \E\left(P_{ij}\right)^2.
\end{align}
Moreover, since $x \mapsto x^2$ is a strictly convex function, Jensen's inequality \cite{Jensen1906, Cover2006} yields
\begin{align}
\E(P_{ij}^2) \geq \E(P_{ij})^2, \label{eq:jensen}
\end{align}
and we find that $\varrho \geq 1$ in networks with symmetric connection probabilities. Jensen's inequality further states that equality in \eqref{eq:jensen}, and thus $\varrho = 1$, holds if and only if $P_{ij}$ follows a degenerate distribution, that is if the distribution of $P_{ij}$ is a constant. In the other case, where the $P_{ij}$ take on more than one value with non-zero probability, we speak of a non-degenerate distribution.

As a central result of this study we thus find that any non-degenerate distribution of symmetric connection probabilities ($P_{ij} = P_{ji}$) necessarily induces an overrepresentation of bidirectional connections in the network, $\varrho > 1$. In other words, in a network where some pairs are more likely connected than others, the count of expected reciprocally connected pairs is strictly underestimated by the statistics of an Erd\H{o}s-R\'{e}nyi graph with same overall connection probability $\E(P_{ij}) = \mu$.

%% ensuring an overrepresentation of bidirectional connections $\varrho > 1$ for any non-degenerate distribution of connection probabilities in the network. In other words, in a network model where some pairs are more likely connected than others, the count of expected reciprocally connected pairs is strictly underestimated by the statistics of an Erd\H{o}s-R\'{e}nyi graph with same overall connection probability $\E(P_{ij}) = \mu$.



%% Finally we can write the expected overrepresentation as
%% \[
%% \varrho = \frac{\E(P_{ij}^2)}{{\E\left(P_{ij}\right)}^2}.
%% \]


